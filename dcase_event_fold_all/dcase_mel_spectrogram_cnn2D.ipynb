{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "import os\n",
    "import keras\n",
    "from os.path import isfile, join\n",
    "import librosa\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Flatten,Conv2D,MaxPooling2D,Dropout\n",
    "import pandas as pd\n",
    "#data_class=np.loadtxt(r\"C:\\Users\\USER\\Desktop\\labels.txt\",delimiter=',')\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from keras.utils import np_utils   \n",
    "import logging\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "#K.set_image_dim_ordering('th')\n",
    "\n",
    "print(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "def _extract_segments(clip, filename):\n",
    "    #clip, filename = args\n",
    "\n",
    "    # Due to an off-by-one bug which has not been caught earlier,\n",
    "    # actually both variants (long and short) use the same\n",
    "    # overlap setting (half of window size) - whereas different settings\n",
    "    # were mentioned in the paper.\n",
    "    #\n",
    "    # The code below has been already cleaned up to reflect those changes.\n",
    "    #\n",
    "    # Apart from that, for reproducibility purposes it is required that\n",
    "    # librosa v0.3.1 is used, as further versions drastically change\n",
    "    # the delta computations.\n",
    "    \n",
    "    FRAMES_PER_SEGMENT = 2 # 41 frames ~= 950 ms segment length @ 22050 Hz\n",
    "    WINDOW_SIZE = 512 * 2  # 23 ms per frame @ 22050 Hz\n",
    "    STEP_SIZE = 512 * 2// 2\n",
    "    BANDS = 60\n",
    "    #sum=np.zeros(60,41)\n",
    "    \n",
    "    s = 0\n",
    "    segments1 = []\n",
    "    segments2=[]\n",
    "    logspec=[]\n",
    "    logspec=np.array(logspec)\n",
    "\n",
    "    normalization_factor = 1 / np.max(np.abs(clip)) \n",
    "    clip = clip * normalization_factor\n",
    "\n",
    "    while len(clip[s * STEP_SIZE:s * STEP_SIZE + WINDOW_SIZE]) == WINDOW_SIZE:\n",
    "        signal = clip[s * STEP_SIZE:s * STEP_SIZE + WINDOW_SIZE]\n",
    "\n",
    "        melspec = librosa.feature.melspectrogram(signal, sr=22050, n_fft=1024, hop_length=512, n_mels=BANDS)\n",
    "        #logspec = librosa.logamplitude(melspec)\n",
    "\n",
    "        delta=librosa.feature.delta(melspec,mode='nearest')\n",
    "        #melspec = melspec.T.flatten()[:, np.newaxis].T\n",
    "        #melspec = pd.DataFrame(data=melspec, dtype='float32', index=[0], columns=list('logspec_b{}_f{}'.format(i % BANDS, i / BANDS) for i in range(np.shape(logspec)[1])))\n",
    "\n",
    "        #if np.mean(logspec.as_matrix()) > -70.0:   # drop silent frames\n",
    "        #segment_meta = pd.DataFrame({'filename': filename,\n",
    "                                        #'s_begin': s * STEP_SIZE, 's_end': s * STEP_SIZE + WINDOW_SIZE,}, index=[0])\n",
    "        #segments.append(pd.concat((segment_meta, logspec), axis=1))\n",
    "        segments1.append(melspec)\n",
    "        segments2.append(delta)\n",
    "        s = s + 1\n",
    "    #for i in range(s-1):\n",
    "        #sum=sum+segments(i,:,:)\n",
    "    #segments=sum/s-1\n",
    "    segments1=np.mean(segments1,axis=0) \n",
    "    segments2=np.mean(segments2,axis=0)\n",
    "\n",
    "    #segments = pd.concat(segments, ignore_index=True)\n",
    "    #libc.malloc_trim(0)\n",
    "    return segments1,segments2\n",
    "print(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataclass=[]\n",
    "dataclass1=[]\n",
    "dataclass2=[]\n",
    "dataclass3=[]\n",
    "dataclass4=[]\n",
    "dataclass5=[]\n",
    "fold1=[]\n",
    "fold2=[]\n",
    "fold3=[]\n",
    "fold4=[]\n",
    "fold5=[]\n",
    "fold11=[]\n",
    "fold22=[]\n",
    "fold33=[]\n",
    "fold44=[]\n",
    "fold55=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features1(onlyfiles,cls,x):\n",
    "    \n",
    "    raw_sounds = []\n",
    "    raw=[]\n",
    "    for i in range(len(onlyfiles)):\n",
    "        X,sr=librosa.load( os.path.join(r\"C:\\internship\\dcase-event-fold\",os.path.join(cls,onlyfiles[i])))\n",
    "        #me2 = np.mean(librosa.feature.melspectrogram(y=X2, sr=sr2, n_mels=40).T,axis=0)\n",
    "        me,ne=_extract_segments(X,onlyfiles[i])\n",
    "        #me2=librosa.feature.melspectrogram(y=X2, sr=sr2, n_mels=60,n_fft=1024,hop_length=512)\n",
    "        raw.append(ne)\n",
    "        #print(me2.shape)\n",
    "        raw_sounds.append(me)\n",
    "        dataclass.append(2)\n",
    "    raw_sounds=np.array(raw_sounds)\n",
    "    raw=np.array(raw)\n",
    "    \n",
    "    \n",
    "    for i in range(len(onlyfiles)):\n",
    "        if(onlyfiles[i][3]=='1'):\n",
    "            fold1.append(raw_sounds[i])\n",
    "            fold11.append(raw[i])\n",
    "            dataclass1.append(x)\n",
    "        elif(onlyfiles[i][3]=='2'):\n",
    "            fold2.append(raw_sounds[i])\n",
    "            fold22.append(raw[i])\n",
    "            dataclass2.append(x)\n",
    "        elif(onlyfiles[i][3]=='3'):\n",
    "            fold3.append(raw_sounds[i])\n",
    "            fold33.append(raw[i])\n",
    "            dataclass3.append(x)\n",
    "        elif(onlyfiles[i][3]=='4'):\n",
    "            fold4.append(raw_sounds[i])\n",
    "            fold44.append(raw[i])\n",
    "            dataclass4.append(x)\n",
    "        elif(onlyfiles[i][3]=='5'):\n",
    "            fold5.append(raw_sounds[i])\n",
    "            fold55.append(raw[i])\n",
    "            dataclass5.append(x)\n",
    "    return raw_sounds,raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 60, 3)\n",
      "(20, 60, 3)\n"
     ]
    }
   ],
   "source": [
    "onlyfiles1 = [f for f in listdir(r\"C:\\internship\\dcase-event-fold\\alert\")if isfile(join(r\"C:\\internship\\dcase-event-fold\\alert\", f))]\n",
    "raw_sounds1=[]\n",
    "raw1=[]\n",
    "raw_sounds1,raw1=extract_features1(onlyfiles1,r\"alert\",1)\n",
    "print(raw_sounds1.shape)\n",
    "print(raw1.shape)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 60, 3)\n",
      "(20, 60, 3)\n"
     ]
    }
   ],
   "source": [
    "onlyfiles2 = [f for f in listdir(r\"C:\\internship\\dcase-event-fold\\clearthroat\") if isfile(join(r\"C:\\internship\\dcase-event-fold\\clearthroat\", f))]\n",
    "raw_sounds2 = []\n",
    "raw2=[]\n",
    "raw_sounds2,raw2=extract_features1(onlyfiles2,r\"clearthroat\",2)\n",
    "print(raw_sounds2.shape)\n",
    "print(raw2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 60, 3)\n",
      "(20, 60, 3)\n"
     ]
    }
   ],
   "source": [
    "onlyfiles3 = [f for f in listdir(r\"C:\\internship\\dcase-event-fold\\cough\") if isfile(join(r\"C:\\internship\\dcase-event-fold\\cough\", f))]\n",
    "raw_sounds3= []\n",
    "raw3=[]\n",
    "raw_sounds3,raw3=extract_features1(onlyfiles3,r\"cough\",3)\n",
    "print(raw_sounds3.shape)\n",
    "print(raw3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 60, 3)\n",
      "(20, 60, 3)\n"
     ]
    }
   ],
   "source": [
    "onlyfiles4 = [f for f in listdir(r\"C:\\internship\\dcase-event-fold\\doorslam\") if isfile(join(r\"C:\\internship\\dcase-event-fold\\doorslam\", f))]\n",
    "raw_sounds4= []\n",
    "raw4=[]\n",
    "raw_sounds4,raw4=extract_features1(onlyfiles4,r\"doorslam\",4)\n",
    "print(raw_sounds4.shape)\n",
    "print(raw4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 60, 3)\n",
      "(20, 60, 3)\n"
     ]
    }
   ],
   "source": [
    "onlyfiles5 = [f for f in listdir(r\"C:\\internship\\dcase-event-fold\\drawer\") if isfile(join(r\"C:\\internship\\dcase-event-fold\\drawer\", f))]\n",
    "raw_sounds5= []\n",
    "raw5=[]\n",
    "raw_sounds5,raw5=extract_features1(onlyfiles5,r\"drawer\",5)\n",
    "print(raw_sounds5.shape)\n",
    "print(raw5.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 60, 3)\n",
      "(20, 60, 3)\n"
     ]
    }
   ],
   "source": [
    "onlyfiles6 = [f for f in listdir(r\"C:\\internship\\dcase-event-fold\\keyboard\") if isfile(join(r\"C:\\internship\\dcase-event-fold\\keyboard\", f))]\n",
    "raw_sounds6= []\n",
    "raw6=[]\n",
    "raw_sounds6,raw6=extract_features1(onlyfiles6,r\"keyboard\",6)\n",
    "print(raw_sounds6.shape)\n",
    "print(raw6.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 60, 3)\n",
      "(20, 60, 3)\n"
     ]
    }
   ],
   "source": [
    "onlyfiles7 = [f for f in listdir(r\"C:\\internship\\dcase-event-fold\\keys\") if isfile(join(r\"C:\\internship\\dcase-event-fold\\keys\", f))]\n",
    "raw_sounds7= []\n",
    "raw7=[]\n",
    "raw_sounds7,raw7=extract_features1(onlyfiles7,r\"keys\",7)\n",
    "print(raw_sounds7.shape)\n",
    "print(raw7.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 60, 3)\n",
      "(20, 60, 3)\n"
     ]
    }
   ],
   "source": [
    "onlyfiles8 = [f for f in listdir(r\"C:\\internship\\dcase-event-fold\\knock\") if isfile(join(r\"C:\\internship\\dcase-event-fold\\knock\", f))]\n",
    "raw_sounds8= []\n",
    "raw8=[]\n",
    "raw_sounds8,raw8=extract_features1(onlyfiles1,r\"knock\",8)\n",
    "print(raw_sounds8.shape)\n",
    "print(raw8.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 60, 3)\n",
      "(20, 60, 3)\n"
     ]
    }
   ],
   "source": [
    "onlyfiles9 = [f for f in listdir(r\"C:\\internship\\dcase-event-fold\\laughter\") if isfile(join(r\"C:\\internship\\dcase-event-fold\\laughter\", f))]\n",
    "raw_sounds9= []\n",
    "raw9=[]\n",
    "raw_sounds9,raw9=extract_features1(onlyfiles9,r\"laughter\",9)\n",
    "print(raw_sounds9.shape)\n",
    "print(raw9.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 60, 3)\n",
      "(20, 60, 3)\n"
     ]
    }
   ],
   "source": [
    "onlyfiles10 = [f for f in listdir(r\"C:\\internship\\dcase-event-fold\\mouse\") if isfile(join(r\"C:\\internship\\dcase-event-fold\\mouse\", f))]\n",
    "raw_sounds10= []\n",
    "raw10=[]\n",
    "raw_sounds10,raw10=extract_features1(onlyfiles10,r\"mouse\",10)\n",
    "print(raw_sounds10.shape)\n",
    "print(raw10.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 60, 3)\n",
      "(20, 60, 3)\n"
     ]
    }
   ],
   "source": [
    "onlyfiles11 = [f for f in listdir(r\"C:\\internship\\dcase-event-fold\\pageturn\") if isfile(join(r\"C:\\internship\\dcase-event-fold\\pageturn\", f))]\n",
    "raw_sounds11= []\n",
    "raw11=[]\n",
    "raw_sounds11,raw11=extract_features1(onlyfiles11,r\"pageturn\",11)\n",
    "print(raw_sounds11.shape)\n",
    "print(raw11.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 60, 3)\n",
      "(20, 60, 3)\n"
     ]
    }
   ],
   "source": [
    "onlyfiles12 = [f for f in listdir(\"C:\\internship\\dcase-event-fold\\pendrop\") if isfile(join(\"C:\\internship\\dcase-event-fold\\pendrop\", f))]\n",
    "raw_sounds12= []\n",
    "raw12=[]\n",
    "raw_sounds12,raw12=extract_features1(onlyfiles12,\"pendrop\",12)\n",
    "print(raw_sounds12.shape)\n",
    "print(raw12.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 60, 3)\n",
      "(20, 60, 3)\n"
     ]
    }
   ],
   "source": [
    "onlyfiles13 = [f for f in listdir(\"C:\\internship\\dcase-event-fold\\phone\") if isfile(join(\"C:\\internship\\dcase-event-fold\\phone\", f))]\n",
    "raw_sounds13= []\n",
    "raw13=[]\n",
    "raw_sounds13,raw13=extract_features1(onlyfiles13,\"phone\",13)\n",
    "print(raw_sounds13.shape)\n",
    "print(raw13.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 60, 3)\n",
      "(20, 60, 3)\n"
     ]
    }
   ],
   "source": [
    "onlyfiles14 = [f for f in listdir(\"C:\\internship\\dcase-event-fold\\printer\") if isfile(join(\"C:\\internship\\dcase-event-fold\\printer\", f))]\n",
    "raw_sounds14= []\n",
    "raw14=[]\n",
    "raw_sounds14,raw14=extract_features1(onlyfiles14,\"printer\",14)\n",
    "print(raw_sounds14.shape)\n",
    "print(raw14.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 60, 3)\n",
      "(20, 60, 3)\n"
     ]
    }
   ],
   "source": [
    "onlyfiles15 = [f for f in listdir(\"C:\\internship\\dcase-event-fold\\speech\") if isfile(join(\"C:\\internship\\dcase-event-fold\\speech\", f))]\n",
    "raw_sounds15= []\n",
    "raw15=[]\n",
    "raw_sounds15,raw15=extract_features1(onlyfiles15,\"speech\",15)\n",
    "print(raw_sounds15.shape)\n",
    "print(raw15.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 60, 3)\n",
      "(20, 60, 3)\n"
     ]
    }
   ],
   "source": [
    "onlyfiles16 = [f for f in listdir(\"C:\\internship\\dcase-event-fold\\switch\") if isfile(join(\"C:\\internship\\dcase-event-fold\\switch\", f))]\n",
    "raw_sounds16= []\n",
    "raw16=[]\n",
    "raw_sounds16,raw16=extract_features1(onlyfiles16,\"switch\",16)\n",
    "print(raw_sounds16.shape)\n",
    "print(raw16.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 60, 3)\n",
      "(64, 60, 3)\n",
      "(64, 60, 3)\n",
      "(64, 60, 3)\n",
      "(64, 60, 3)\n"
     ]
    }
   ],
   "source": [
    "fold1=np.array(fold1)\n",
    "print(fold1.shape)\n",
    "fold2=np.array(fold2)\n",
    "print(fold2.shape)\n",
    "fold3=np.array(fold3)\n",
    "print(fold3.shape)\n",
    "fold4=np.array(fold4)\n",
    "print(fold4.shape)\n",
    "fold5=np.array(fold5)\n",
    "print(fold5.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 60, 3)\n",
      "(64, 60, 3)\n",
      "(64, 60, 3)\n",
      "(64, 60, 3)\n",
      "(64, 60, 3)\n"
     ]
    }
   ],
   "source": [
    "fold11=np.array(fold11)\n",
    "print(fold11.shape)\n",
    "fold22=np.array(fold22)\n",
    "print(fold22.shape)\n",
    "fold33=np.array(fold33)\n",
    "print(fold33.shape)\n",
    "fold44=np.array(fold44)\n",
    "print(fold44.shape)\n",
    "fold55=np.array(fold55)\n",
    "print(fold55.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "print(len(dataclass1))\n",
    "print(len(dataclass2))\n",
    "print(len(dataclass3))\n",
    "print(len(dataclass4))\n",
    "print(len(dataclass5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 60, 3)\n",
      "(256,)\n",
      "(256, 60, 3)\n"
     ]
    }
   ],
   "source": [
    "train=[]\n",
    "train_x=np.vstack([fold2,fold3,fold4,fold5])\n",
    "train1_x=np.vstack([fold22,fold33,fold44,fold55])\n",
    "train_x=np.array(train_x)\n",
    "train_y=dataclass2+dataclass3+dataclass4+dataclass5\n",
    "print (train_x.shape)\n",
    "train_y=np.array(train_y)\n",
    "print (train_y.shape)\n",
    "print (train1_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 16)\n"
     ]
    }
   ],
   "source": [
    "labelencoder_train=LabelEncoder()\n",
    "labelencoder_train.fit(train_y)\n",
    "data_cl=labelencoder_train.transform(train_y)\n",
    "dummy_class_train=np_utils.to_categorical(data_cl)\n",
    "print (dummy_class_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 16)\n"
     ]
    }
   ],
   "source": [
    "labelencoder_test=LabelEncoder()\n",
    "labelencoder_test.fit(dataclass1)\n",
    "data_cl=labelencoder_test.transform(dataclass1)\n",
    "dummy_class_test=np_utils.to_categorical(data_cl)\n",
    "print (dummy_class_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 60, 3, 1)\n",
      "(256, 60, 3, 1)\n",
      "(64, 60, 3, 1)\n",
      "(64, 60, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "train_xx = np.expand_dims(train_x, axis=3)\n",
    "print(train_xx.shape)\n",
    "train1_xx = np.expand_dims(train1_x, axis=3)\n",
    "print(train1_xx.shape)\n",
    "foldi= np.expand_dims(fold1, axis=3)\n",
    "print(foldi.shape)\n",
    "foldii= np.expand_dims(fold11, axis=3)\n",
    "print(foldii.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 2, 60, 3)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2_xx=[]\n",
    "train2_xx=np.array(train2_xx)\n",
    "train2_xx=np.concatenate((train_xx,train1_xx),axis=3)\n",
    "train2_xx=train2_xx.reshape(256,2,60,3)\n",
    "train2_xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 2, 60, 3)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "foldf=np.concatenate((foldi,foldii),axis=3)\n",
    "foldf=foldf.reshape(64,2,60,3)\n",
    "foldf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#random.seed(167)\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Conv2D(80, kernel_size=(1,1),activation='relu',input_shape=(2,60,3)))\n",
    "#model.add(Batchnormalization())\n",
    "model.add(MaxPooling2D(pool_size=(1,1), strides=(1, 3)))\n",
    "\n",
    "\n",
    "model.add(Dropout(.5))\n",
    "model.add(Conv2D(filters=80,kernel_size=(1,1),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(1,1),strides=(1,3)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "#model.add(Dense(num_classes, activation='softmax'))\n",
    "#model.add(Dense(500, activation='relu',input_dim=40))\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(16, activation='softmax'))\n",
    "#model.add(Dropout(0.1))\n",
    "#model.add(Dense(500, activation='relu'))\n",
    "#model.add(Dropout(0.1))\n",
    "#model.add(Dense(100, activation='relu'))\n",
    "#model.add(Dropout(0.1))\n",
    "#model.add(Dense(12, activation='softmax'))\n",
    "#train_xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "epochs = 300\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 5.9909 - acc: 0.0781\n",
      "Epoch 2/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 4.8573 - acc: 0.1172\n",
      "Epoch 3/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 4.3531 - acc: 0.1758\n",
      "Epoch 4/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 4.1539 - acc: 0.1523\n",
      "Epoch 5/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 3.4769 - acc: 0.1953\n",
      "Epoch 6/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 3.3517 - acc: 0.1836\n",
      "Epoch 7/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 3.4088 - acc: 0.1680\n",
      "Epoch 8/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 3.1102 - acc: 0.1641\n",
      "Epoch 9/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 3.1000 - acc: 0.1875\n",
      "Epoch 10/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 2.7379 - acc: 0.2188\n",
      "Epoch 11/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 2.8510 - acc: 0.2227\n",
      "Epoch 12/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 2.8820 - acc: 0.1953\n",
      "Epoch 13/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 2.6897 - acc: 0.2305\n",
      "Epoch 14/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 2.7206 - acc: 0.1992\n",
      "Epoch 15/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 2.5558 - acc: 0.2187\n",
      "Epoch 16/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 2.6529 - acc: 0.2109\n",
      "Epoch 17/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 2.5894 - acc: 0.2148\n",
      "Epoch 18/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 2.5891 - acc: 0.2031\n",
      "Epoch 19/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 2.4249 - acc: 0.2305\n",
      "Epoch 20/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 2.3368 - acc: 0.2773\n",
      "Epoch 21/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 2.3796 - acc: 0.2969\n",
      "Epoch 22/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 2.3244 - acc: 0.2578\n",
      "Epoch 23/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 2.3801 - acc: 0.2617\n",
      "Epoch 24/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 2.2824 - acc: 0.2969\n",
      "Epoch 25/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 2.2274 - acc: 0.2930\n",
      "Epoch 26/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 2.4026 - acc: 0.2500\n",
      "Epoch 27/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 2.1854 - acc: 0.2969\n",
      "Epoch 28/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 2.2007 - acc: 0.2891\n",
      "Epoch 29/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 2.2975 - acc: 0.2422\n",
      "Epoch 30/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 2.0682 - acc: 0.3242\n",
      "Epoch 31/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 2.2742 - acc: 0.3438\n",
      "Epoch 32/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 2.1630 - acc: 0.3203\n",
      "Epoch 33/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 2.0071 - acc: 0.3516\n",
      "Epoch 34/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 2.0308 - acc: 0.3359\n",
      "Epoch 35/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 2.1210 - acc: 0.3242\n",
      "Epoch 36/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 2.1608 - acc: 0.3008\n",
      "Epoch 37/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.9950 - acc: 0.3633\n",
      "Epoch 38/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 2.0238 - acc: 0.3437\n",
      "Epoch 39/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.9329 - acc: 0.3516\n",
      "Epoch 40/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.9052 - acc: 0.3867\n",
      "Epoch 41/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.9005 - acc: 0.4102\n",
      "Epoch 42/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.9668 - acc: 0.3906\n",
      "Epoch 43/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.9925 - acc: 0.3359\n",
      "Epoch 44/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.8942 - acc: 0.3711\n",
      "Epoch 45/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.9142 - acc: 0.4023\n",
      "Epoch 46/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.8145 - acc: 0.4180\n",
      "Epoch 47/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.8215 - acc: 0.3984\n",
      "Epoch 48/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.8766 - acc: 0.3750\n",
      "Epoch 49/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.7103 - acc: 0.4531\n",
      "Epoch 50/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.7566 - acc: 0.4336\n",
      "Epoch 51/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.7885 - acc: 0.4219\n",
      "Epoch 52/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.7704 - acc: 0.4297\n",
      "Epoch 53/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.6775 - acc: 0.4102\n",
      "Epoch 54/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.7934 - acc: 0.3984\n",
      "Epoch 55/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.7229 - acc: 0.3945\n",
      "Epoch 56/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.7250 - acc: 0.4023\n",
      "Epoch 57/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.7167 - acc: 0.4609\n",
      "Epoch 58/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.6830 - acc: 0.4609\n",
      "Epoch 59/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.6343 - acc: 0.4414\n",
      "Epoch 60/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.6261 - acc: 0.4375\n",
      "Epoch 61/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.5620 - acc: 0.4648\n",
      "Epoch 62/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.6078 - acc: 0.4727\n",
      "Epoch 63/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.6238 - acc: 0.4687\n",
      "Epoch 64/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.5746 - acc: 0.4648\n",
      "Epoch 65/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.4964 - acc: 0.5117\n",
      "Epoch 66/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.5333 - acc: 0.5000\n",
      "Epoch 67/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.4670 - acc: 0.4883\n",
      "Epoch 68/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.5580 - acc: 0.4766\n",
      "Epoch 69/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.5467 - acc: 0.4961\n",
      "Epoch 70/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.5296 - acc: 0.4414\n",
      "Epoch 71/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.6617 - acc: 0.4219\n",
      "Epoch 72/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.5152 - acc: 0.4492\n",
      "Epoch 73/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.5180 - acc: 0.4883\n",
      "Epoch 74/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.4472 - acc: 0.4922\n",
      "Epoch 75/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.4878 - acc: 0.4922\n",
      "Epoch 76/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.4470 - acc: 0.5469\n",
      "Epoch 77/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.4835 - acc: 0.5234\n",
      "Epoch 78/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.4089 - acc: 0.4883\n",
      "Epoch 79/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.4068 - acc: 0.5234\n",
      "Epoch 80/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.2795 - acc: 0.5547\n",
      "Epoch 81/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.4101 - acc: 0.5391\n",
      "Epoch 82/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.4029 - acc: 0.5352\n",
      "Epoch 83/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.3382 - acc: 0.5352\n",
      "Epoch 84/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.3559 - acc: 0.5430\n",
      "Epoch 85/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.3911 - acc: 0.5430\n",
      "Epoch 86/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.3594 - acc: 0.5273\n",
      "Epoch 87/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.3155 - acc: 0.5625\n",
      "Epoch 88/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.3034 - acc: 0.5430\n",
      "Epoch 89/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.3326 - acc: 0.5898\n",
      "Epoch 90/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.3701 - acc: 0.5547\n",
      "Epoch 91/300\n",
      "256/256 [==============================] - 0s 977us/step - loss: 1.2500 - acc: 0.5508\n",
      "Epoch 92/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.2692 - acc: 0.5625\n",
      "Epoch 93/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.2458 - acc: 0.5859\n",
      "Epoch 94/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.3656 - acc: 0.5469\n",
      "Epoch 95/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.3103 - acc: 0.5352\n",
      "Epoch 96/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.2585 - acc: 0.5469\n",
      "Epoch 97/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.2663 - acc: 0.5898\n",
      "Epoch 98/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.3379 - acc: 0.5469\n",
      "Epoch 99/300\n",
      "256/256 [==============================] - 0s 977us/step - loss: 1.1919 - acc: 0.5508\n",
      "Epoch 100/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.3099 - acc: 0.5547\n",
      "Epoch 101/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.2193 - acc: 0.5508\n",
      "Epoch 102/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.1953 - acc: 0.5781\n",
      "Epoch 103/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.2523 - acc: 0.5742\n",
      "Epoch 104/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.2893 - acc: 0.5898\n",
      "Epoch 105/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.2882 - acc: 0.5664\n",
      "Epoch 106/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.2296 - acc: 0.5937\n",
      "Epoch 107/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.0688 - acc: 0.6367\n",
      "Epoch 108/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.1181 - acc: 0.6055\n",
      "Epoch 109/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.1516 - acc: 0.6172\n",
      "Epoch 110/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.0629 - acc: 0.6094\n",
      "Epoch 111/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.1075 - acc: 0.5703\n",
      "Epoch 112/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.1437 - acc: 0.6211\n",
      "Epoch 113/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.0766 - acc: 0.5898\n",
      "Epoch 114/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.1258 - acc: 0.5781\n",
      "Epoch 115/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.9753 - acc: 0.6445\n",
      "Epoch 116/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.1326 - acc: 0.6328\n",
      "Epoch 117/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.0709 - acc: 0.6406\n",
      "Epoch 118/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.1449 - acc: 0.6484\n",
      "Epoch 119/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.0703 - acc: 0.6406\n",
      "Epoch 120/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.0684 - acc: 0.6172\n",
      "Epoch 121/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.9470 - acc: 0.6563\n",
      "Epoch 122/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.9985 - acc: 0.6445\n",
      "Epoch 123/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.1145 - acc: 0.6211\n",
      "Epoch 124/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.0242 - acc: 0.6016\n",
      "Epoch 125/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.9976 - acc: 0.6172\n",
      "Epoch 126/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.0928 - acc: 0.6133\n",
      "Epoch 127/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.1009 - acc: 0.6289\n",
      "Epoch 128/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.1200 - acc: 0.6211\n",
      "Epoch 129/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.0265 - acc: 0.6641\n",
      "Epoch 130/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.0141 - acc: 0.6406\n",
      "Epoch 131/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.9314 - acc: 0.6641\n",
      "Epoch 132/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.1467 - acc: 0.6250\n",
      "Epoch 133/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.0154 - acc: 0.6250\n",
      "Epoch 134/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.9398 - acc: 0.6445\n",
      "Epoch 135/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.9841 - acc: 0.6641\n",
      "Epoch 136/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.0569 - acc: 0.6250\n",
      "Epoch 137/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.9263 - acc: 0.6836\n",
      "Epoch 138/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.9813 - acc: 0.6602\n",
      "Epoch 139/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.8964 - acc: 0.6680\n",
      "Epoch 140/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.9702 - acc: 0.6680\n",
      "Epoch 141/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.9421 - acc: 0.6445\n",
      "Epoch 142/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.9073 - acc: 0.6563\n",
      "Epoch 143/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.9256 - acc: 0.6953\n",
      "Epoch 144/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.8972 - acc: 0.6992\n",
      "Epoch 145/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.9543 - acc: 0.6953\n",
      "Epoch 146/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.8683 - acc: 0.6875\n",
      "Epoch 147/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.9067 - acc: 0.7070\n",
      "Epoch 148/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.8121 - acc: 0.6992\n",
      "Epoch 149/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.8914 - acc: 0.6758\n",
      "Epoch 150/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.8606 - acc: 0.7070\n",
      "Epoch 151/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.7890 - acc: 0.7578\n",
      "Epoch 152/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.9274 - acc: 0.7070\n",
      "Epoch 153/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.8546 - acc: 0.7109\n",
      "Epoch 154/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.9101 - acc: 0.6953\n",
      "Epoch 155/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.7986 - acc: 0.6992\n",
      "Epoch 156/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.8452 - acc: 0.7109A: 0s - loss: 0.8506 - acc: 0.712\n",
      "Epoch 157/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.8065 - acc: 0.6758\n",
      "Epoch 158/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.7910 - acc: 0.7227\n",
      "Epoch 159/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.8816 - acc: 0.6758\n",
      "Epoch 160/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.8953 - acc: 0.7109\n",
      "Epoch 161/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.7453 - acc: 0.7656\n",
      "Epoch 162/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.8228 - acc: 0.7500\n",
      "Epoch 163/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.7370 - acc: 0.7266\n",
      "Epoch 164/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.8128 - acc: 0.7109\n",
      "Epoch 165/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.8579 - acc: 0.7187\n",
      "Epoch 166/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.7224 - acc: 0.7305\n",
      "Epoch 167/300\n",
      "256/256 [==============================] - 0s 977us/step - loss: 0.7595 - acc: 0.7305\n",
      "Epoch 168/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 0s 1ms/step - loss: 0.8373 - acc: 0.7187\n",
      "Epoch 169/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.7686 - acc: 0.7422\n",
      "Epoch 170/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.6622 - acc: 0.7852\n",
      "Epoch 171/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.8342 - acc: 0.7188\n",
      "Epoch 172/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.6774 - acc: 0.7656\n",
      "Epoch 173/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.7104 - acc: 0.7617\n",
      "Epoch 174/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.7764 - acc: 0.7305\n",
      "Epoch 175/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.7006 - acc: 0.7383\n",
      "Epoch 176/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.7002 - acc: 0.7461\n",
      "Epoch 177/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.6761 - acc: 0.7500\n",
      "Epoch 178/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.7209 - acc: 0.7383\n",
      "Epoch 179/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.7867 - acc: 0.7031\n",
      "Epoch 180/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.7023 - acc: 0.7539\n",
      "Epoch 181/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.6843 - acc: 0.7461\n",
      "Epoch 182/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.6851 - acc: 0.7539\n",
      "Epoch 183/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.6802 - acc: 0.7656\n",
      "Epoch 184/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.6390 - acc: 0.7773\n",
      "Epoch 185/300\n",
      "256/256 [==============================] - 0s 977us/step - loss: 0.7672 - acc: 0.7266\n",
      "Epoch 186/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.7505 - acc: 0.7383\n",
      "Epoch 187/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.6616 - acc: 0.7969\n",
      "Epoch 188/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.7093 - acc: 0.7422\n",
      "Epoch 189/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.7378 - acc: 0.7344\n",
      "Epoch 190/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.6611 - acc: 0.7617\n",
      "Epoch 191/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.6927 - acc: 0.7578\n",
      "Epoch 192/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.6436 - acc: 0.7500\n",
      "Epoch 193/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.7326 - acc: 0.7344\n",
      "Epoch 194/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.6235 - acc: 0.7539\n",
      "Epoch 195/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.7199 - acc: 0.7461\n",
      "Epoch 196/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.7812 - acc: 0.7461\n",
      "Epoch 197/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.7254 - acc: 0.7461\n",
      "Epoch 198/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.6244 - acc: 0.7617\n",
      "Epoch 199/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.6246 - acc: 0.7695\n",
      "Epoch 200/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.7143 - acc: 0.7773\n",
      "Epoch 201/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.7192 - acc: 0.7813\n",
      "Epoch 202/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5985 - acc: 0.7461\n",
      "Epoch 203/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.6877 - acc: 0.7812\n",
      "Epoch 204/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.6762 - acc: 0.7891\n",
      "Epoch 205/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5984 - acc: 0.7617\n",
      "Epoch 206/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.6030 - acc: 0.8086\n",
      "Epoch 207/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.6101 - acc: 0.8164\n",
      "Epoch 208/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5653 - acc: 0.7812\n",
      "Epoch 209/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5830 - acc: 0.8125\n",
      "Epoch 210/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.7061 - acc: 0.7656\n",
      "Epoch 211/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5365 - acc: 0.8281\n",
      "Epoch 212/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5544 - acc: 0.8086\n",
      "Epoch 213/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.6004 - acc: 0.7891\n",
      "Epoch 214/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.6932 - acc: 0.7812\n",
      "Epoch 215/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.6090 - acc: 0.7891\n",
      "Epoch 216/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5688 - acc: 0.7813\n",
      "Epoch 217/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5787 - acc: 0.7773\n",
      "Epoch 218/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.6190 - acc: 0.7813\n",
      "Epoch 219/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5402 - acc: 0.8008\n",
      "Epoch 220/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.6041 - acc: 0.7891\n",
      "Epoch 221/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5243 - acc: 0.7812\n",
      "Epoch 222/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5422 - acc: 0.8047\n",
      "Epoch 223/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.7109 - acc: 0.7695\n",
      "Epoch 224/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5951 - acc: 0.7930\n",
      "Epoch 225/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.6552 - acc: 0.8047\n",
      "Epoch 226/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5705 - acc: 0.7773\n",
      "Epoch 227/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5211 - acc: 0.8203\n",
      "Epoch 228/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.6213 - acc: 0.7930\n",
      "Epoch 229/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5036 - acc: 0.8437\n",
      "Epoch 230/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.4864 - acc: 0.8320\n",
      "Epoch 231/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5527 - acc: 0.8047\n",
      "Epoch 232/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5106 - acc: 0.8086\n",
      "Epoch 233/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5782 - acc: 0.8164\n",
      "Epoch 234/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.6194 - acc: 0.7773\n",
      "Epoch 235/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.4420 - acc: 0.8398\n",
      "Epoch 236/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5218 - acc: 0.8164\n",
      "Epoch 237/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.6306 - acc: 0.8164\n",
      "Epoch 238/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.4840 - acc: 0.8164\n",
      "Epoch 239/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.6532 - acc: 0.7969\n",
      "Epoch 240/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5094 - acc: 0.7969\n",
      "Epoch 241/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.6181 - acc: 0.7930\n",
      "Epoch 242/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5861 - acc: 0.7617\n",
      "Epoch 243/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5469 - acc: 0.7734\n",
      "Epoch 244/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.4377 - acc: 0.8477\n",
      "Epoch 245/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.4714 - acc: 0.8281\n",
      "Epoch 246/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5518 - acc: 0.8164\n",
      "Epoch 247/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.4499 - acc: 0.8359\n",
      "Epoch 248/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.4744 - acc: 0.8047\n",
      "Epoch 249/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5629 - acc: 0.8047\n",
      "Epoch 250/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5816 - acc: 0.8281\n",
      "Epoch 251/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5483 - acc: 0.7969\n",
      "Epoch 252/300\n",
      "256/256 [==============================] - ETA: 0s - loss: 0.5250 - acc: 0.820 - 0s 1ms/step - loss: 0.5180 - acc: 0.8203\n",
      "Epoch 253/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.4522 - acc: 0.8242\n",
      "Epoch 254/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5151 - acc: 0.8164\n",
      "Epoch 255/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5294 - acc: 0.8164\n",
      "Epoch 256/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.4462 - acc: 0.8359\n",
      "Epoch 257/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5020 - acc: 0.8437\n",
      "Epoch 258/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.4140 - acc: 0.8516\n",
      "Epoch 259/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.4458 - acc: 0.8359\n",
      "Epoch 260/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.3668 - acc: 0.8516\n",
      "Epoch 261/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.4223 - acc: 0.8555\n",
      "Epoch 262/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5016 - acc: 0.8398\n",
      "Epoch 263/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.4994 - acc: 0.8359\n",
      "Epoch 264/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5418 - acc: 0.8125\n",
      "Epoch 265/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.4891 - acc: 0.8555\n",
      "Epoch 266/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5625 - acc: 0.8125\n",
      "Epoch 267/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5787 - acc: 0.8008\n",
      "Epoch 268/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5219 - acc: 0.8320\n",
      "Epoch 269/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.3908 - acc: 0.8477\n",
      "Epoch 270/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.4380 - acc: 0.8320\n",
      "Epoch 271/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.4424 - acc: 0.8828\n",
      "Epoch 272/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5156 - acc: 0.8125\n",
      "Epoch 273/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5250 - acc: 0.8008\n",
      "Epoch 274/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.4780 - acc: 0.8437\n",
      "Epoch 275/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5263 - acc: 0.8242\n",
      "Epoch 276/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.4615 - acc: 0.8516\n",
      "Epoch 277/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.4573 - acc: 0.8398\n",
      "Epoch 278/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.4559 - acc: 0.8320\n",
      "Epoch 279/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.4683 - acc: 0.8320\n",
      "Epoch 280/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.4219 - acc: 0.8164\n",
      "Epoch 281/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.4512 - acc: 0.8320\n",
      "Epoch 282/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5269 - acc: 0.8164\n",
      "Epoch 283/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.4359 - acc: 0.8203\n",
      "Epoch 284/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.4553 - acc: 0.8359\n",
      "Epoch 285/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.4629 - acc: 0.8281\n",
      "Epoch 286/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.4799 - acc: 0.8477\n",
      "Epoch 287/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.4866 - acc: 0.8437\n",
      "Epoch 288/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5026 - acc: 0.8086\n",
      "Epoch 289/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.3605 - acc: 0.8672\n",
      "Epoch 290/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.4394 - acc: 0.8437\n",
      "Epoch 291/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.4181 - acc: 0.8633\n",
      "Epoch 292/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.4114 - acc: 0.8867\n",
      "Epoch 293/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.3147 - acc: 0.8945\n",
      "Epoch 294/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.3778 - acc: 0.8555\n",
      "Epoch 295/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.3687 - acc: 0.8672\n",
      "Epoch 296/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.4395 - acc: 0.8555\n",
      "Epoch 297/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5649 - acc: 0.8281\n",
      "Epoch 298/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.4229 - acc: 0.8477\n",
      "Epoch 299/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.4609 - acc: 0.8437\n",
      "Epoch 300/300\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.3899 - acc: 0.8555\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train2_xx, dummy_class_train, batch_size=batch_size, epochs=epochs, verbose=1)#, validation_data=(fold5,dummy_class_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.2866156697273254, 0.453125]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(foldf,dummy_class_test, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
