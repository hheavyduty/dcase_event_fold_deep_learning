{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "import os\n",
    "import keras\n",
    "from os.path import isfile, join\n",
    "import librosa\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Flatten,Conv2D,MaxPooling2D,Dropout,Reshape,LSTM,Conv1D,MaxPooling1D,SimpleRNN\n",
    "import pandas as pd\n",
    "#data_class=np.loadtxt(r\"C:\\Users\\USER\\Desktop\\labels.txt\",delimiter=',')\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from keras.utils import np_utils   \n",
    "from sklearn.metrics import f1_score\n",
    "import logging\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from sklearn.svm import SVC \n",
    "#K.set_image_dim_ordering('th')\n",
    "from keras.models import Model\n",
    "from sklearn import tree\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestClassifier,VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#from hmmlearn import hmm\n",
    "print(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "def _extract_segments(clip, filename):\n",
    "    \n",
    "    \n",
    "    FRAMES_PER_SEGMENT = 49  # 41 frames ~= 950 ms segment length @ 22050 Hz\n",
    "    WINDOW_SIZE = 512 * 49   # 23 ms per frame @ 22050 Hz\n",
    "    STEP_SIZE = 512 * 49 // 2\n",
    "    BANDS = 60\n",
    "    #sum=np.zeros(60,41)\n",
    "    \n",
    "    s = 0\n",
    "    segments1 = []\n",
    "    #segments2=[]\n",
    "    #logspec=[]\n",
    "    #logspec=np.array(logspec)\n",
    "\n",
    "    normalization_factor = 1 / np.max(np.abs(clip)) \n",
    "    clip = clip * normalization_factor\n",
    "\n",
    "    while len(clip[s * STEP_SIZE:s * STEP_SIZE + WINDOW_SIZE]) == WINDOW_SIZE:\n",
    "        signal = clip[s * STEP_SIZE:s * STEP_SIZE + WINDOW_SIZE]\n",
    "\n",
    "        melspec = librosa.feature.mfcc(signal, sr=22050, n_fft=1024, hop_length=512, n_mfcc=BANDS)\n",
    "        #logspec = librosa.logamplitude(melspec)\n",
    "\n",
    "        #delta=librosa.feature.delta(melspec,mode='nearest')\n",
    "        \n",
    "        segments1.append(melspec)\n",
    "        #segments2.append(delta)\n",
    "        s = s + 1\n",
    "    #for i in range(s-1):\n",
    "        #sum=sum+segments(i,:,:)\n",
    "    #segments=sum/s-1\n",
    "    segments1=np.mean(segments1,axis=0) \n",
    "    #segments2=np.mean(segments2,axis=0)\n",
    "\n",
    "    #segments = pd.concat(segments, ignore_index=True)\n",
    "    #libc.malloc_trim(0)\n",
    "    return segments1\n",
    "print(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "dataclass1=[]\n",
    "dataclass2=[]\n",
    "dataclass3=[]\n",
    "dataclass4=[]\n",
    "fold1=[]\n",
    "fold2=[]\n",
    "fold3=[]\n",
    "fold4=[]\n",
    "def extract_features1(dataset_path):\n",
    "    onlyfiles = [f for f in listdir(dataset_path)]\n",
    "    for j in range(len(onlyfiles)):\n",
    "        aud_file=[f for f in listdir(os.path.join(dataset_path,onlyfiles[j]))]        \n",
    "        for i in range(len(aud_file)):\n",
    "            if(aud_file[i][1]=='1'):\n",
    "                wav_file=[f for f in listdir(os.path.join(dataset_path,os.path.join(onlyfiles[j],aud_file[i])))]\n",
    "                for k in range(len(wav_file)):\n",
    "                    X,sr=librosa.load( os.path.join(dataset_path,os.path.join(onlyfiles[j],os.path.join(aud_file[i],wav_file[k]))))\n",
    "                    me1=_extract_segments(X,wav_file[k])\n",
    "                    fold1.append(me1)\n",
    "                    dataclass1.append(j)\n",
    "            elif(aud_file[i][1]=='2'):\n",
    "                wav_file=[f for f in listdir(os.path.join(dataset_path,os.path.join(onlyfiles[j],aud_file[i])))]\n",
    "                for k in range(len(wav_file)):\n",
    "                    X,sr=librosa.load( os.path.join(dataset_path,os.path.join(onlyfiles[j],os.path.join(aud_file[i],wav_file[k]))))                    \n",
    "                    me2=_extract_segments(X,wav_file[k])\n",
    "                    fold2.append(me2)\n",
    "                    dataclass2.append(j)\n",
    "            elif(aud_file[i][1]=='3'):\n",
    "                wav_file=[f for f in listdir(os.path.join(dataset_path,os.path.join(onlyfiles[j],aud_file[i])))]\n",
    "                for k in range(len(wav_file)):\n",
    "                    X,sr=librosa.load( os.path.join(dataset_path,os.path.join(onlyfiles[j],os.path.join(aud_file[i],wav_file[k]))))\n",
    "                    me3=_extract_segments(X,wav_file[k])\n",
    "                    fold3.append(me3)\n",
    "                    dataclass3.append(j)\n",
    "            elif(aud_file[i][1]=='4'):\n",
    "                wav_file=[f for f in listdir(os.path.join(dataset_path,os.path.join(onlyfiles[j],aud_file[i])))]\n",
    "                for k in range(len(wav_file)):\n",
    "                    X,sr=librosa.load( os.path.join(dataset_path,os.path.join(onlyfiles[j],os.path.join(aud_file[i],wav_file[k]))))\n",
    "                    me4=_extract_segments(X,wav_file[k])\n",
    "                    fold4.append(me4)\n",
    "                    dataclass4.append(j)\n",
    "   # return  fold1,fold2,fold3,fold4,fold5,dataclass1,dataclass2,dataclass3,dataclasss4,dataclass5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 60, 50)\n",
      "(70, 60, 50)\n",
      "(70, 60, 50)\n",
      "(70, 60, 50)\n"
     ]
    }
   ],
   "source": [
    "extract_features1(r\"C:\\internship\\sonidosSubir\\allSounds\\testdataclean\")\n",
    "print((np.array(fold1)).shape)\n",
    "print((np.array(fold2)).shape)\n",
    "print((np.array(fold3)).shape)\n",
    "print((np.array(fold4)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 60, 50)\n",
      "210\n"
     ]
    }
   ],
   "source": [
    "train_x=np.vstack([fold1,fold2,fold3])\n",
    "train_y=dataclass1+dataclass2+dataclass3\n",
    "print(train_x.shape)\n",
    "\n",
    "print(len(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 7)\n"
     ]
    }
   ],
   "source": [
    "labelencoder_train=LabelEncoder()\n",
    "labelencoder_train.fit(train_y)\n",
    "data_cl=labelencoder_train.transform(train_y)\n",
    "dummy_class_train=np_utils.to_categorical(data_cl)\n",
    "print (dummy_class_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 7)\n"
     ]
    }
   ],
   "source": [
    "labelencoder_train=LabelEncoder()\n",
    "labelencoder_train.fit(dataclass4)\n",
    "data_cl=labelencoder_train.transform(dataclass4)\n",
    "dummy_class_test=np_utils.to_categorical(data_cl)\n",
    "print (dummy_class_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 60, 50, 1)\n"
     ]
    }
   ],
   "source": [
    "train_xx=np.expand_dims((train_x),axis=3)\n",
    "print(train_xx.shape)\n",
    "#train_xx=np.reshape((train_x),(210,60,50,1))\n",
    "#train_xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 60, 50, 1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_xx=np.expand_dims((fold4),axis=3)\n",
    "test_xx.shape\n",
    "test_xx=np.reshape((fold4),(70,60,50,1))\n",
    "test_xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "model=Sequential()\n",
    "'''\n",
    "model.add(Conv1D(filters=200, kernel_size=5, input_shape=(3000,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=5 ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(filters=200, kernel_size=5))\n",
    "model.add(MaxPooling1D(pool_size=5 ))\n",
    "model.add(BatchNormalization())\n",
    "'''#model.add(Conv1D(filters=10, kernel_size=5))\n",
    "#model.add(MaxPooling1D(pool_size=5 ))\n",
    "\n",
    "model.add(Conv2D(100, kernel_size=(5,5),activation='relu',input_shape=(60,50,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(1, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(.1))\n",
    "model.add(Conv2D(filters=100,kernel_size=(1,1),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(1,1),strides=(1,3)))\n",
    "model.add(BatchNormalization())\n",
    "#model.add(Conv2D(filters=100,kernel_size=(1,1),activation='relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(1,1),strides=(1,3)))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Reshape((100, -1)))\n",
    "#'''\n",
    "#model.add(SimpleRNN(500,activation='tanh',input_shape=(3000,1)))\n",
    "#model.add(LSTM(100,activation='tanh',input_shape=(1600,1)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Reshape((1, -1)))\n",
    "model.add(Flatten())\n",
    "#model.add(Dense(500, activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Dropout(0.1))\n",
    "#model.add(Dense(num_classes, activation='softmax'))\n",
    "#model.add(Dense(500, activation='relu'))\n",
    "#model.add(Dropout(0.1))\n",
    "#model.add(Dense(500, activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "#clf = hmm.GaussianHMM()\n",
    "clf = SVC(kernel='poly',degree=4)\n",
    "#clf1=SVC(kernel='poly',degree=3)\n",
    "#clf2=SVC(kernel='poly',degree=5)\n",
    "#clf3=SVC(kernel='poly',degree=2)\n",
    "#clf1 = tree.DecisionTreeClassifier()\n",
    "#clf2=RandomForestClassifier()\n",
    "#clf3=GaussianNB()\n",
    "#eclf1 = VotingClassifier(estimators=[('svm', clf), ('gnb',clf3)])\n",
    "#clf=linear_model.LogisticRegression()\n",
    "#model.add(Dense(7, activation='softmax'))\n",
    "#model.add(Dropout(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 56, 46, 100)       2600      \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 56, 46, 100)       400       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 55, 45, 100)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 55, 45, 100)       400       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 55, 45, 100)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 55, 45, 100)       10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 55, 45, 100)       400       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 55, 15, 100)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 55, 15, 100)       400       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 55, 15, 100)       0         \n",
      "_________________________________________________________________\n",
      "reshape_5 (Reshape)          (None, 1, 82500)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 82500)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 500)               41250500  \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 500)               2000      \n",
      "=================================================================\n",
      "Total params: 41,266,800\n",
      "Trainable params: 41,265,000\n",
      "Non-trainable params: 1,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 500)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_3rd_layer_output = K.function([model.layers[0].input],\n",
    "                                  [model.layers[13].output])\n",
    "layer_output = get_3rd_layer_output([train_xx])[0]\n",
    "layer_output.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 500)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_output_train=np.reshape((layer_output),(210,500))\n",
    "layer_output_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 500)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_3rd_layer_output1 = K.function([model.layers[0].input],\n",
    "                                  [model.layers[13].output])\n",
    "layer_output_1= get_3rd_layer_output1([test_xx])[0]\n",
    "layer_output_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 500)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_output_test=np.reshape((layer_output_1),(70,500))\n",
    "layer_output_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=4, gamma='auto', kernel='poly',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(layer_output_train,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(layer_output_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66580576849339523"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(dataclass4, y_pred,average='macro') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#y_pred = svclassifier.predict(test_xx)\n",
    "#y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "210/210 [==============================] - 37s 176ms/step - loss: 1.8245 - acc: 0.2238\n",
      "Epoch 2/5\n",
      "210/210 [==============================] - 38s 179ms/step - loss: 1.7941 - acc: 0.2524\n",
      "Epoch 3/5\n",
      "210/210 [==============================] - 38s 179ms/step - loss: 1.8111 - acc: 0.2333\n",
      "Epoch 4/5\n",
      "210/210 [==============================] - 38s 182ms/step - loss: 1.8027 - acc: 0.2429\n",
      "Epoch 5/5\n",
      "210/210 [==============================] - 38s 180ms/step - loss: 1.8224 - acc: 0.2143\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_2 (SimpleRNN)     (None, 100)               10200     \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 1, 100)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 707       \n",
      "=================================================================\n",
      "Total params: 10,907\n",
      "Trainable params: 10,907\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_xx, dummy_class_train, batch_size=1, epochs=5)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 6, 3, 3, 6, 1, 1, 6, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 3, 6, 3, 3, 3, 6, 6, 3, 6, 6,\n",
       "       6, 3, 6, 6, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 6, 5, 3, 3, 6, 6, 6, 0, 6,\n",
       "       6], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict_classes(test_xx)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[13.272114310945783, 0.17142856972558157]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_xx,dummy_class_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
